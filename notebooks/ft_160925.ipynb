{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0406cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df8a16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df = pd.read_csv('../data/processed/master_panel.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['date'] >= '2021-01-01']\n",
    "df.head().to_csv('../data/processed/master_panel_head.csv', index=False)\n",
    "\n",
    "# manipulate date column so that every 3 month is actually a year \n",
    "# jan-mar 2021 -> 1995, apr-jun 2021 -> 1996, jul-sep 2021 -> 1997, oct-dec 2021 -> 1998, etc\n",
    "quarters_since_2021 = ((df['date'].dt.year - 2021) * 4) + ((df['date'].dt.month - 1) // 3)\n",
    "months_in_year = (df['date'].dt.month - 1) % 12\n",
    "df['date'] = pd.to_datetime('1995-01-01') + pd.to_timedelta(quarters_since_2021 * 365, unit='D') + pd.to_timedelta(months_in_year * 30, unit='D')\n",
    "df.to_csv('../data/processed/master_panel_2021_onwards.csv', index=False)\"\"\"\n",
    "df = pd.read_csv('../data/processed/master_panel.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00a2e30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ml_research_kills_alpha.support.constants import PREDICTED_COL\n",
    "# drop column where PREDICTED_COL is NaN\n",
    "df = df.dropna(subset=PREDICTED_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd28d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 16:59:10,091 [INFO] RollingTrainer initialized for years 2005 to 2007 with target column: 'ret'\n"
     ]
    }
   ],
   "source": [
    "from ml_research_kills_alpha.modeling.rolling_trainer import RollingTrainer\n",
    "from ml_research_kills_alpha.modeling.algorithms.elastic_net import ElasticNetModel\n",
    "from ml_research_kills_alpha.modeling.algorithms.huber_ols import HuberRegressorModel\n",
    "from ml_research_kills_alpha.modeling.algorithms.neural_networks import FFNNModel\n",
    "\n",
    "models = [ElasticNetModel(), HuberRegressorModel(), FFNNModel(2), FFNNModel(3), FFNNModel(4), FFNNModel(5)]\n",
    "trainer = RollingTrainer(models=models, data=df, end_year=2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e404bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 16:59:10,170 [INFO] Training models for test year 2005...\n",
      "2025-10-01 16:59:10,178 [INFO] Year 2005: Using 102 valid features out of 212 total features.\n",
      "C:\\Users\\ftibe\\OneDrive\\Desktop\\ml-research-kills-alpha\\ml_research_kills_alpha\\modeling\\rolling_trainer.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_data[self.year_col] = pd.to_datetime(features_data[self.year_col])\n",
      "2025-10-01 16:59:13,693 [INFO] Year 2005: Train data from start to 1998, Validation data from 1999 to 2004, Test data for 2005.\n",
      "2025-10-01 16:59:14,734 [INFO] Training model: ENET for year 2005\n",
      "2025-10-01 16:59:30,787 [INFO] Evaluating model: ENET for year 2005, month 2005-02\n",
      "2025-10-01 16:59:30,819 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:30,854 [INFO] Evaluating model: ENET for year 2005, month 2005-03\n",
      "2025-10-01 16:59:30,873 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:30,882 [INFO] Evaluating model: ENET for year 2005, month 2005-04\n",
      "2025-10-01 16:59:30,901 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:30,909 [INFO] Evaluating model: ENET for year 2005, month 2005-05\n",
      "2025-10-01 16:59:30,929 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:30,937 [INFO] Evaluating model: ENET for year 2005, month 2005-06\n",
      "2025-10-01 16:59:30,952 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:30,958 [INFO] Evaluating model: ENET for year 2005, month 2005-07\n",
      "2025-10-01 16:59:30,974 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:30,981 [INFO] Evaluating model: ENET for year 2005, month 2005-08\n",
      "2025-10-01 16:59:30,996 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:31,002 [INFO] Evaluating model: ENET for year 2005, month 2005-09\n",
      "2025-10-01 16:59:31,018 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:31,027 [INFO] Evaluating model: ENET for year 2005, month 2005-10\n",
      "2025-10-01 16:59:31,043 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:31,053 [INFO] Evaluating model: ENET for year 2005, month 2005-11\n",
      "2025-10-01 16:59:31,070 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:31,077 [INFO] Evaluating model: ENET for year 2005, month 2005-12\n",
      "2025-10-01 16:59:31,096 [INFO] Generated predictions for ENET\n",
      "2025-10-01 16:59:31,105 [INFO] Training model: OLS-H for year 2005\n",
      "2025-10-01 17:01:34,064 [INFO] Evaluating model: OLS-H for year 2005, month 2005-02\n",
      "2025-10-01 17:01:34,084 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,092 [INFO] Evaluating model: OLS-H for year 2005, month 2005-03\n",
      "2025-10-01 17:01:34,107 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,114 [INFO] Evaluating model: OLS-H for year 2005, month 2005-04\n",
      "2025-10-01 17:01:34,128 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,134 [INFO] Evaluating model: OLS-H for year 2005, month 2005-05\n",
      "2025-10-01 17:01:34,148 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,153 [INFO] Evaluating model: OLS-H for year 2005, month 2005-06\n",
      "2025-10-01 17:01:34,167 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,315 [INFO] Evaluating model: OLS-H for year 2005, month 2005-07\n",
      "2025-10-01 17:01:34,327 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,332 [INFO] Evaluating model: OLS-H for year 2005, month 2005-08\n",
      "2025-10-01 17:01:34,345 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,350 [INFO] Evaluating model: OLS-H for year 2005, month 2005-09\n",
      "2025-10-01 17:01:34,362 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,367 [INFO] Evaluating model: OLS-H for year 2005, month 2005-10\n",
      "2025-10-01 17:01:34,379 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,383 [INFO] Evaluating model: OLS-H for year 2005, month 2005-11\n",
      "2025-10-01 17:01:34,396 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,401 [INFO] Evaluating model: OLS-H for year 2005, month 2005-12\n",
      "2025-10-01 17:01:34,413 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 17:01:34,418 [INFO] Training model: FFNN2 for year 2005\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m results = \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml-research-kills-alpha\\ml_research_kills_alpha\\modeling\\rolling_trainer.py:203\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    200\u001b[39m for year in range(self.start_year, self.end_year + 1):\n\u001b[32m    201\u001b[39m     self.logger.info(f\"Training models for test year {year}...\")\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     # Split data into training, validation, and test sets\n\u001b[32m    204\u001b[39m     train_data, val_data, test_data = self.train_val_test_split(year)\n\u001b[32m    206\u001b[39m     # Prepare data for modeling\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml-research-kills-alpha\\ml_research_kills_alpha\\modeling\\rolling_trainer.py:132\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(self, model, X_train, y_train, X_val, y_val, year, test_sorted, months, preds_all, train)\u001b[39m\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model: Modeler,\n\u001b[32m    126\u001b[39m               X_train: pd.Series, y_train: pd.Series,\n\u001b[32m    127\u001b[39m               X_val: pd.Series, y_val: pd.Series,\n\u001b[32m    128\u001b[39m               year: \u001b[38;5;28mint\u001b[39m, test_sorted: pd.DataFrame,\n\u001b[32m    129\u001b[39m               months: pd.Series, preds_all: \u001b[38;5;28mlist\u001b[39m,\n\u001b[32m    130\u001b[39m               train: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mTrue\u001b[39;00m) -> \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mlist\u001b[39m]:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m132\u001b[39m \u001b[33;03m    Train and evaluate a single model for a specific year.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m    135\u001b[39m \u001b[33;03m        model (Modeler): the model to train and evaluate.\u001b[39;00m\n\u001b[32m    136\u001b[39m \u001b[33;03m        X_train (pd.Series): training features.\u001b[39;00m\n\u001b[32m    137\u001b[39m \u001b[33;03m        y_train (pd.Series): training target.\u001b[39;00m\n\u001b[32m    138\u001b[39m \u001b[33;03m        X_val (pd.Series): validation features.\u001b[39;00m\n\u001b[32m    139\u001b[39m \u001b[33;03m        y_val (pd.Series): validation target.\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[33;03m        year (int): the test year.\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m        test_sorted (pd.DataFrame): sorted test data for evaluation.\u001b[39;00m\n\u001b[32m    142\u001b[39m \u001b[33;03m        months (pd.Series): unique months in the test data.\u001b[39;00m\n\u001b[32m    143\u001b[39m \u001b[33;03m        preds_all (list): list to append predictions to.\u001b[39;00m\n\u001b[32m    144\u001b[39m \u001b[33;03m        train (bool): whether to train the model or not - for ensembles is False.\u001b[39;00m\n\u001b[32m    145\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    146\u001b[39m     \u001b[38;5;28mself\u001b[39m.logger.info(\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    147\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m train:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\OneDrive\\Desktop\\ml-research-kills-alpha\\ml_research_kills_alpha\\modeling\\algorithms\\neural_networks.py:167\u001b[39m, in \u001b[36mFFNNModel.train\u001b[39m\u001b[34m(self, X_train, y_train, X_val, y_val)\u001b[39m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(X_train), batch_size):\n\u001b[32m    166\u001b[39m     idx = permutation[i:i+batch_size]\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     batch_X = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m     batch_y = torch.tensor(y_train[idx], dtype=torch.float32, device=device)\n\u001b[32m    169\u001b[39m     optimizer.zero_grad()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "results = trainer.run()\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
