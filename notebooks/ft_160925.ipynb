{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0406cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8a16cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"df = pd.read_csv('../data/processed/master_panel.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['date'] >= '2021-01-01']\n",
    "df.head().to_csv('../data/processed/master_panel_head.csv', index=False)\n",
    "\n",
    "# manipulate date column so that every 3 month is actually a year \n",
    "# jan-mar 2021 -> 1995, apr-jun 2021 -> 1996, jul-sep 2021 -> 1997, oct-dec 2021 -> 1998, etc\n",
    "quarters_since_2021 = ((df['date'].dt.year - 2021) * 4) + ((df['date'].dt.month - 1) // 3)\n",
    "months_in_year = (df['date'].dt.month - 1) % 12\n",
    "df['date'] = pd.to_datetime('1995-01-01') + pd.to_timedelta(quarters_since_2021 * 365, unit='D') + pd.to_timedelta(months_in_year * 30, unit='D')\n",
    "df.to_csv('../data/processed/master_panel_2021_onwards.csv', index=False)\"\"\"\n",
    "df = pd.read_csv('../data/processed/master_panel_2021_onwards.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a2e30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-01 14:08:03.723\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mml_research_kills_alpha.config\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m11\u001b[0m - \u001b[1mPROJ_ROOT path is: C:\\Users\\ftibe\\OneDrive\\Desktop\\ml-research-kills-alpha\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ml_research_kills_alpha.support.constants import PREDICTED_COL\n",
    "# drop column where PREDICTED_COL is NaN\n",
    "df = df.dropna(subset=PREDICTED_COL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd28d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 14:08:11,989 [INFO] RollingTrainer initialized for years 2005 to 2007 with target column: 'ret'\n"
     ]
    }
   ],
   "source": [
    "from ml_research_kills_alpha.modeling.rolling_trainer import RollingTrainer\n",
    "from ml_research_kills_alpha.modeling.algorithms.elastic_net import ElasticNetModel\n",
    "from ml_research_kills_alpha.modeling.algorithms.huber_ols import HuberRegressorModel\n",
    "from ml_research_kills_alpha.modeling.algorithms.neural_networks import FFNNModel\n",
    "\n",
    "models = [ElasticNetModel(alpha=0.0001, l1_ratio=0.9), HuberRegressorModel(alpha=0.0001, epsilon=1.5), FFNNModel(2), FFNNModel(3), FFNNModel(4), FFNNModel(5)]\n",
    "trainer = RollingTrainer(models=models, data=df, end_year=2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41e404bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-01 14:08:12,000 [INFO] Training models for test year 2005...\n",
      "2025-10-01 14:08:12,002 [INFO] Year 2005: Using 102 valid features out of 212 total features.\n",
      "C:\\Users\\ftibe\\OneDrive\\Desktop\\ml-research-kills-alpha\\ml_research_kills_alpha\\modeling\\rolling_trainer.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_data[self.year_col] = pd.to_datetime(features_data[self.year_col])\n",
      "2025-10-01 14:08:12,121 [INFO] Year 2005: Train data from start to 1998, Validation data from 1999 to 2004, Test data for 2005.\n",
      "2025-10-01 14:08:12,161 [INFO] Training model: ENET for year 2005\n",
      "2025-10-01 14:08:16,913 [INFO] Evaluating model: ENET for year 2005, month 2005-07\n",
      "2025-10-01 14:08:16,934 [INFO] Generated predictions for ENET\n",
      "2025-10-01 14:08:16,940 [INFO] Evaluating model: ENET for year 2005, month 2005-08\n",
      "2025-10-01 14:08:16,951 [INFO] Generated predictions for ENET\n",
      "2025-10-01 14:08:16,956 [INFO] Training model: OLS-H for year 2005\n",
      "2025-10-01 14:08:22,893 [INFO] Evaluating model: OLS-H for year 2005, month 2005-07\n",
      "2025-10-01 14:08:22,902 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 14:08:22,906 [INFO] Evaluating model: OLS-H for year 2005, month 2005-08\n",
      "2025-10-01 14:08:22,916 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 14:08:22,921 [INFO] Training model: FFNN2 for year 2005\n",
      "2025-10-01 14:08:50,606 [INFO] Training complete for network 1. Best validation loss: 0.020977\n",
      "2025-10-01 14:09:28,157 [INFO] Training complete for network 2. Best validation loss: 0.020847\n",
      "2025-10-01 14:10:02,094 [INFO] Training complete for network 3. Best validation loss: 0.019505\n",
      "2025-10-01 14:10:23,479 [INFO] Training complete for network 4. Best validation loss: 0.022765\n",
      "2025-10-01 14:10:48,236 [INFO] Training complete for network 5. Best validation loss: 0.021001\n",
      "2025-10-01 14:10:48,237 [INFO] Evaluating model: FFNN2 for year 2005, month 2005-07\n",
      "2025-10-01 14:10:48,262 [INFO] Generated predictions for FFNN2\n",
      "2025-10-01 14:10:48,275 [INFO] Evaluating model: FFNN2 for year 2005, month 2005-08\n",
      "2025-10-01 14:10:48,298 [INFO] Generated predictions for FFNN2\n",
      "2025-10-01 14:10:48,305 [INFO] Training model: FFNN3 for year 2005\n",
      "2025-10-01 14:11:20,486 [INFO] Training complete for network 1. Best validation loss: 0.020507\n",
      "2025-10-01 14:11:50,420 [INFO] Training complete for network 2. Best validation loss: 0.016576\n",
      "2025-10-01 14:12:21,468 [INFO] Training complete for network 3. Best validation loss: 0.019831\n",
      "2025-10-01 14:12:53,594 [INFO] Training complete for network 4. Best validation loss: 0.021964\n",
      "2025-10-01 14:13:08,183 [INFO] Training complete for network 5. Best validation loss: 0.016094\n",
      "2025-10-01 14:13:08,185 [INFO] Evaluating model: FFNN3 for year 2005, month 2005-07\n",
      "2025-10-01 14:13:08,208 [INFO] Generated predictions for FFNN3\n",
      "2025-10-01 14:13:08,214 [INFO] Evaluating model: FFNN3 for year 2005, month 2005-08\n",
      "2025-10-01 14:13:08,239 [INFO] Generated predictions for FFNN3\n",
      "2025-10-01 14:13:08,245 [INFO] Training model: FFNN4 for year 2005\n",
      "2025-10-01 14:13:29,108 [INFO] Training complete for network 1. Best validation loss: 0.021499\n",
      "2025-10-01 14:13:45,943 [INFO] Training complete for network 2. Best validation loss: 0.021695\n",
      "2025-10-01 14:14:06,522 [INFO] Training complete for network 3. Best validation loss: 0.021159\n",
      "2025-10-01 14:14:39,239 [INFO] Training complete for network 4. Best validation loss: 0.014282\n",
      "2025-10-01 14:15:01,667 [INFO] Training complete for network 5. Best validation loss: 0.019941\n",
      "2025-10-01 14:15:01,669 [INFO] Evaluating model: FFNN4 for year 2005, month 2005-07\n",
      "2025-10-01 14:15:01,692 [INFO] Generated predictions for FFNN4\n",
      "2025-10-01 14:15:01,698 [INFO] Evaluating model: FFNN4 for year 2005, month 2005-08\n",
      "2025-10-01 14:15:01,725 [INFO] Generated predictions for FFNN4\n",
      "2025-10-01 14:15:01,732 [INFO] Training model: FFNN5 for year 2005\n",
      "2025-10-01 14:15:21,014 [INFO] Training complete for network 1. Best validation loss: 0.021160\n",
      "2025-10-01 14:15:52,897 [INFO] Training complete for network 2. Best validation loss: 0.020021\n",
      "2025-10-01 14:16:43,972 [INFO] Training complete for network 3. Best validation loss: 0.016965\n",
      "2025-10-01 14:17:13,596 [INFO] Training complete for network 4. Best validation loss: 0.020543\n",
      "2025-10-01 14:17:50,779 [INFO] Training complete for network 5. Best validation loss: 0.015473\n",
      "2025-10-01 14:17:50,781 [INFO] Evaluating model: FFNN5 for year 2005, month 2005-07\n",
      "2025-10-01 14:17:50,811 [INFO] Generated predictions for FFNN5\n",
      "2025-10-01 14:17:50,817 [INFO] Evaluating model: FFNN5 for year 2005, month 2005-08\n",
      "2025-10-01 14:17:50,846 [INFO] Generated predictions for FFNN5\n",
      "2025-10-01 14:17:50,851 [INFO] Using pre-trained model: Ensemble for year 2005\n",
      "2025-10-01 14:17:50,852 [INFO] Evaluating model: Ensemble for year 2005, month 2005-07\n",
      "2025-10-01 14:17:50,873 [INFO] Generated predictions for FFNN2\n",
      "2025-10-01 14:17:50,883 [INFO] Generated predictions for FFNN3\n",
      "2025-10-01 14:17:50,896 [INFO] Generated predictions for FFNN4\n",
      "2025-10-01 14:17:50,912 [INFO] Generated predictions for FFNN5\n",
      "2025-10-01 14:17:50,918 [INFO] Evaluating model: Ensemble for year 2005, month 2005-08\n",
      "2025-10-01 14:17:50,941 [INFO] Generated predictions for FFNN2\n",
      "2025-10-01 14:17:50,952 [INFO] Generated predictions for FFNN3\n",
      "2025-10-01 14:17:50,965 [INFO] Generated predictions for FFNN4\n",
      "2025-10-01 14:17:50,982 [INFO] Generated predictions for FFNN5\n",
      "2025-10-01 14:17:50,989 [INFO] Training models for test year 2006...\n",
      "2025-10-01 14:17:50,992 [INFO] Year 2006: Using 130 valid features out of 212 total features.\n",
      "C:\\Users\\ftibe\\OneDrive\\Desktop\\ml-research-kills-alpha\\ml_research_kills_alpha\\modeling\\rolling_trainer.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_data[self.year_col] = pd.to_datetime(features_data[self.year_col])\n",
      "2025-10-01 14:17:51,114 [INFO] Year 2006: Train data from start to 1999, Validation data from 2000 to 2005, Test data for 2006.\n",
      "2025-10-01 14:17:51,172 [INFO] Training model: ENET for year 2006\n",
      "2025-10-01 14:18:00,914 [INFO] Evaluating model: ENET for year 2006, month 2006-10\n",
      "2025-10-01 14:18:00,929 [INFO] Generated predictions for ENET\n",
      "2025-10-01 14:18:00,937 [INFO] Evaluating model: ENET for year 2006, month 2006-11\n",
      "2025-10-01 14:18:00,953 [INFO] Generated predictions for ENET\n",
      "2025-10-01 14:18:00,958 [INFO] Training model: OLS-H for year 2006\n",
      "2025-10-01 14:18:12,064 [INFO] Evaluating model: OLS-H for year 2006, month 2006-10\n",
      "2025-10-01 14:18:12,077 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 14:18:12,082 [INFO] Evaluating model: OLS-H for year 2006, month 2006-11\n",
      "2025-10-01 14:18:12,096 [INFO] Generated predictions for OLS-H\n",
      "2025-10-01 14:18:12,101 [INFO] Training model: FFNN2 for year 2006\n",
      "2025-10-01 14:18:45,099 [INFO] Training complete for network 1. Best validation loss: 0.020823\n",
      "2025-10-01 14:19:09,236 [INFO] Training complete for network 2. Best validation loss: 0.018890\n",
      "2025-10-01 14:19:35,407 [INFO] Training complete for network 3. Best validation loss: 0.022397\n",
      "2025-10-01 14:20:14,667 [INFO] Training complete for network 4. Best validation loss: 0.022419\n",
      "2025-10-01 14:20:45,217 [INFO] Training complete for network 5. Best validation loss: 0.019064\n",
      "2025-10-01 14:20:45,218 [INFO] Evaluating model: FFNN2 for year 2006, month 2006-10\n",
      "2025-10-01 14:20:45,243 [INFO] Generated predictions for FFNN2\n",
      "2025-10-01 14:20:45,251 [INFO] Evaluating model: FFNN2 for year 2006, month 2006-11\n",
      "2025-10-01 14:20:45,279 [INFO] Generated predictions for FFNN2\n",
      "2025-10-01 14:20:45,287 [INFO] Training model: FFNN3 for year 2006\n",
      "2025-10-01 14:21:24,236 [INFO] Training complete for network 1. Best validation loss: 0.013743\n",
      "2025-10-01 14:21:39,580 [INFO] Training complete for network 2. Best validation loss: 0.020202\n",
      "2025-10-01 14:22:01,059 [INFO] Training complete for network 3. Best validation loss: 0.019632\n",
      "2025-10-01 14:22:31,387 [INFO] Training complete for network 4. Best validation loss: 0.018547\n",
      "2025-10-01 14:22:56,374 [INFO] Training complete for network 5. Best validation loss: 0.021415\n",
      "2025-10-01 14:22:56,375 [INFO] Evaluating model: FFNN3 for year 2006, month 2006-10\n",
      "2025-10-01 14:22:56,398 [INFO] Generated predictions for FFNN3\n",
      "2025-10-01 14:22:56,402 [INFO] Evaluating model: FFNN3 for year 2006, month 2006-11\n",
      "2025-10-01 14:22:56,421 [INFO] Generated predictions for FFNN3\n",
      "2025-10-01 14:22:56,425 [INFO] Training model: FFNN4 for year 2006\n",
      "2025-10-01 14:23:14,836 [INFO] Training complete for network 1. Best validation loss: 0.021046\n",
      "2025-10-01 14:23:24,840 [INFO] Training complete for network 2. Best validation loss: 0.019928\n",
      "2025-10-01 14:23:54,752 [INFO] Training complete for network 3. Best validation loss: 0.019923\n",
      "2025-10-01 14:24:12,512 [INFO] Training complete for network 4. Best validation loss: 0.017997\n",
      "2025-10-01 14:24:41,875 [INFO] Training complete for network 5. Best validation loss: 0.020533\n",
      "2025-10-01 14:24:41,876 [INFO] Evaluating model: FFNN4 for year 2006, month 2006-10\n",
      "2025-10-01 14:24:41,900 [INFO] Generated predictions for FFNN4\n",
      "2025-10-01 14:24:41,906 [INFO] Evaluating model: FFNN4 for year 2006, month 2006-11\n",
      "2025-10-01 14:24:41,928 [INFO] Generated predictions for FFNN4\n",
      "2025-10-01 14:24:41,934 [INFO] Training model: FFNN5 for year 2006\n",
      "2025-10-01 14:25:18,891 [INFO] Training complete for network 1. Best validation loss: 0.015021\n",
      "2025-10-01 14:25:44,663 [INFO] Training complete for network 2. Best validation loss: 0.015473\n",
      "2025-10-01 14:26:08,125 [INFO] Training complete for network 3. Best validation loss: 0.021428\n",
      "2025-10-01 14:26:28,582 [INFO] Training complete for network 4. Best validation loss: 0.021164\n",
      "2025-10-01 14:26:53,596 [INFO] Training complete for network 5. Best validation loss: 0.014580\n",
      "2025-10-01 14:26:53,597 [INFO] Evaluating model: FFNN5 for year 2006, month 2006-10\n",
      "2025-10-01 14:26:53,621 [INFO] Generated predictions for FFNN5\n",
      "2025-10-01 14:26:53,626 [INFO] Evaluating model: FFNN5 for year 2006, month 2006-11\n",
      "2025-10-01 14:26:53,649 [INFO] Generated predictions for FFNN5\n",
      "2025-10-01 14:26:53,654 [INFO] Using pre-trained model: Ensemble for year 2006\n",
      "2025-10-01 14:26:53,655 [INFO] Evaluating model: Ensemble for year 2006, month 2006-10\n",
      "2025-10-01 14:26:53,673 [INFO] Generated predictions for FFNN2\n",
      "2025-10-01 14:26:53,680 [INFO] Generated predictions for FFNN3\n",
      "2025-10-01 14:26:53,689 [INFO] Generated predictions for FFNN4\n",
      "2025-10-01 14:26:53,700 [INFO] Generated predictions for FFNN5\n",
      "2025-10-01 14:26:53,705 [INFO] Evaluating model: Ensemble for year 2006, month 2006-11\n",
      "2025-10-01 14:26:53,722 [INFO] Generated predictions for FFNN2\n",
      "2025-10-01 14:26:53,729 [INFO] Generated predictions for FFNN3\n",
      "2025-10-01 14:26:53,737 [INFO] Generated predictions for FFNN4\n",
      "2025-10-01 14:26:53,748 [INFO] Generated predictions for FFNN5\n",
      "2025-10-01 14:26:53,753 [INFO] Training models for test year 2007...\n",
      "2025-10-01 14:26:53,754 [INFO] Year 2007: Using 139 valid features out of 212 total features.\n",
      "C:\\Users\\ftibe\\OneDrive\\Desktop\\ml-research-kills-alpha\\ml_research_kills_alpha\\modeling\\rolling_trainer.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_data[self.year_col] = pd.to_datetime(features_data[self.year_col])\n",
      "2025-10-01 14:26:53,881 [INFO] Year 2007: Train data from start to 2000, Validation data from 2001 to 2006, Test data for 2007.\n",
      "2025-10-01 14:26:53,937 [INFO] Training model: ENET for year 2007\n",
      "2025-10-01 14:27:01,177 [INFO] Training model: OLS-H for year 2007\n",
      "2025-10-01 14:27:12,489 [INFO] Training model: FFNN2 for year 2007\n",
      "2025-10-01 14:27:46,882 [INFO] Training complete for network 1. Best validation loss: 0.023261\n",
      "2025-10-01 14:28:21,454 [INFO] Training complete for network 2. Best validation loss: 0.020821\n",
      "2025-10-01 14:28:59,203 [INFO] Training complete for network 3. Best validation loss: 0.021964\n",
      "2025-10-01 14:29:37,846 [INFO] Training complete for network 4. Best validation loss: 0.019332\n",
      "2025-10-01 14:30:09,149 [INFO] Training complete for network 5. Best validation loss: 0.023584\n",
      "2025-10-01 14:30:09,150 [INFO] Training model: FFNN3 for year 2007\n",
      "2025-10-01 14:30:44,356 [INFO] Training complete for network 1. Best validation loss: 0.019730\n",
      "2025-10-01 14:31:22,069 [INFO] Training complete for network 2. Best validation loss: 0.019959\n",
      "2025-10-01 14:32:02,712 [INFO] Training complete for network 3. Best validation loss: 0.018803\n",
      "2025-10-01 14:32:27,100 [INFO] Training complete for network 4. Best validation loss: 0.022807\n",
      "2025-10-01 14:33:07,276 [INFO] Training complete for network 5. Best validation loss: 0.016274\n",
      "2025-10-01 14:33:07,277 [INFO] Training model: FFNN4 for year 2007\n",
      "2025-10-01 14:33:28,546 [INFO] Training complete for network 1. Best validation loss: 0.022273\n",
      "2025-10-01 14:34:02,027 [INFO] Training complete for network 2. Best validation loss: 0.025088\n",
      "2025-10-01 14:34:44,112 [INFO] Training complete for network 3. Best validation loss: 0.024341\n",
      "2025-10-01 14:35:27,576 [INFO] Training complete for network 4. Best validation loss: 0.019189\n",
      "2025-10-01 14:36:04,903 [INFO] Training complete for network 5. Best validation loss: 0.019361\n",
      "2025-10-01 14:36:04,905 [INFO] Training model: FFNN5 for year 2007\n",
      "2025-10-01 14:36:39,507 [INFO] Training complete for network 1. Best validation loss: 0.018494\n",
      "2025-10-01 14:37:09,586 [INFO] Training complete for network 2. Best validation loss: 0.019930\n",
      "2025-10-01 14:37:46,275 [INFO] Training complete for network 3. Best validation loss: 0.017889\n",
      "2025-10-01 14:37:59,785 [INFO] Training complete for network 4. Best validation loss: 0.021398\n",
      "2025-10-01 14:38:17,224 [INFO] Training complete for network 5. Best validation loss: 0.023172\n",
      "2025-10-01 14:38:17,225 [INFO] Using pre-trained model: Ensemble for year 2007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(        permno     date     model     y_hat\n",
       " 0        10026  2005-06      ENET -0.076688\n",
       " 1        58975  2005-06      ENET  0.218504\n",
       " 2        59010  2005-06      ENET  0.146924\n",
       " 3        59045  2005-06      ENET  0.095936\n",
       " 4        59176  2005-06      ENET -0.179940\n",
       " ...        ...      ...       ...       ...\n",
       " 114648   19619  2006-10  Ensemble -0.260419\n",
       " 114649   19599  2006-10  Ensemble  0.179575\n",
       " 114650   19616  2006-10  Ensemble  0.203629\n",
       " 114651   19606  2006-10  Ensemble  0.204912\n",
       " 114652   19621  2006-10  Ensemble -0.211896\n",
       " \n",
       " [114653 rows x 4 columns],\n",
       " {2005: {'ENET': np.float64(0.06511993902190005),\n",
       "   'OLS-H': np.float64(0.05518062684180777),\n",
       "   'FFNN2': np.float64(0.06859847395324638),\n",
       "   'FFNN3': np.float64(0.07344433219805974),\n",
       "   'FFNN4': np.float64(0.07453351304217773),\n",
       "   'FFNN5': np.float64(0.07857221270520967),\n",
       "   'Ensemble': np.float64(0.0728585398412025)},\n",
       "  2006: {'ENET': np.float64(0.1180492593499001),\n",
       "   'OLS-H': np.float64(0.11111439536196804),\n",
       "   'FFNN2': np.float64(0.1213712671640865),\n",
       "   'FFNN3': np.float64(0.12573473986471218),\n",
       "   'FFNN4': np.float64(0.12666834241463806),\n",
       "   'FFNN5': np.float64(0.13062884808860403),\n",
       "   'Ensemble': np.float64(0.12533135590318834)},\n",
       "  2007: {'ENET': None,\n",
       "   'OLS-H': None,\n",
       "   'FFNN2': None,\n",
       "   'FFNN3': None,\n",
       "   'FFNN4': None,\n",
       "   'FFNN5': None,\n",
       "   'Ensemble': None}})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = trainer.run()\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
